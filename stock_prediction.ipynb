{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "DATAPATH = 'sample/stock_prices_sample.csv'\n",
    "data = pd.read_csv(DATAPATH, index_col=['DATE'], parse_dates=['DATE'])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "data = data[data.TICKER != 'GEF']\n",
    "data = data[data.TYPE != 'Intraday']\n",
    "\n",
    "drop_cols = ['VOLUME','SPLIT_RATIO', 'EX_DIVIDEND', 'ADJ_FACTOR', 'ADJ_VOLUME', 'ADJ_CLOSE', 'ADJ_LOW', 'ADJ_HIGH', 'ADJ_OPEN', 'FREQUENCY', 'TYPE', 'FIGI']\n",
    "data.drop(drop_cols, axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot closing price\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(data.CLOSE)\n",
    "plt.title('Closing price of New GF Inc')\n",
    "plt.ylabel('Closing price ($)')\n",
    "plt.xlabel('Trading day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving average model \n",
    "#the next observation is the mean of all past observations\n",
    "#moving average model uses past forecast errors in a regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def plt_moving_avg(series, window, plot_intervals=False, scale=1.96):\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.title('Moving Avg \\n Window size = {}'.format(window))\n",
    "    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n",
    "\n",
    "    #plot confidence intervals for smooth values by the previous week/month/quater data\n",
    "    if plot_intervals:\n",
    "        mean_abs_err = mean_absolute_error(series[window:], rolling_mean[window:])\n",
    "        deviation = np.std(series[window:] - rolling_mean[window:])\n",
    "        lower_bound = rolling_mean - (mean_abs_err + scale * deviation)\n",
    "        upper_bound = rolling_mean + (mean_abs_err + scale * deviation)\n",
    "\n",
    "        plt.plot(upper_bound, 'r--', label='Upper bound / Lower bound')\n",
    "        plt.plot(lower_bound, 'r--')\n",
    "\n",
    "    plt.plot(series[window:], label='Actual values')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "#smooth by previous 5 days\n",
    "plt_moving_avg(data.CLOSE, 5)\n",
    "#smooth by previous month\n",
    "plt_moving_avg(data.CLOSE, 30)\n",
    "#smooth by previous quarter\n",
    "plt_moving_avg(data.CLOSE, 90, plot_intervals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exponential smoothing\n",
    "#assigns exponentially decreasing weights over time to the past observations\n",
    "#less importance is given to observations as we move further from the present\n",
    "def expo_smoothing(series, alpha):\n",
    "    result = [series[0]] # first value as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1]) #yð‘¡=âˆxð‘¡+(1âˆ’âˆ)yð‘¡âˆ’1, ð‘¡>0 and alpha is smoothing factor\n",
    "    return result\n",
    "  \n",
    "def plot_expo_smoothing(series, alphas):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    for alpha in alphas:\n",
    "        plt.plot(expo_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n",
    "    plt.plot(series.values, \"c\", label = \"Actual\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.axis('tight')\n",
    "    plt.title(\"Exponential smoothing\")\n",
    "    plt.grid(True);\n",
    "\n",
    "plot_expo_smoothing(data.CLOSE, [0.05, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "#when we make a model for forecasting purposes in time series analysis, we require a stationary time series for better prediction.\n",
    "#ADF Fuller test is a statistical test used to check for stationarity in time series. \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "def tsplot(y, lags=None, figsize=(15, 7), syle='bmh'):    \n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style='bmh'):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2,2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1,0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1,1))\n",
    "        y.plot(ax=ts_ax)\n",
    "        p_value = adfuller(y)[1]\n",
    "        ts_ax.set_title('Time series analysis\\n Dickey-Fuller: p={0:.5f}'.format(p_value))\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "tsplot(data.CLOSE, lags=30)\n",
    "\n",
    "# Take the first difference to remove to make the process stationary\n",
    "data_diff = data.CLOSE - data.CLOSE.shift(1)\n",
    "\n",
    "tsplot(data_diff[1:], lags=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMA\n",
    "# - we first need to define a few parameters and a range of values for \n",
    "# other parameters to generate a list of all possible combinations of p, q, d, P, Q, D, s.\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Set initial values and some bounds\n",
    "ps = range(0, 5)\n",
    "d = 1\n",
    "qs = range(0, 5)\n",
    "Ps = range(0, 5)\n",
    "D = 1\n",
    "Qs = range(0, 5)\n",
    "s = 5\n",
    "\n",
    "#Create a list with all possible combinations of parameters\n",
    "params = product(ps, qs, Ps, Qs)\n",
    "params_list = list(params)\n",
    "len(params_list)\n",
    "\n",
    "# Train many SARIMA models to find the best set of params\n",
    "def optimize_SARIMA(params_list, d, D, s):\n",
    "    \"\"\" Return dataframe with params and corresponding AIC\n",
    "        params_list - list with (p, q, P, Q) tuples\n",
    "        d - integration order\n",
    "        D - seasonal integration order\n",
    "        s - length of season\n",
    "    \"\"\"    \n",
    "    results = []\n",
    "    best_aic = float('inf')\n",
    "    \n",
    "    for param in tqdm_notebook(params_list):\n",
    "        try: \n",
    "            model = sm.tsa.statespace.SARIMAX(data.CLOSE, order=(param[0], d, param[1]),\n",
    "                                              seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n",
    "        except:\n",
    "            continue\n",
    "        aic = model.aic\n",
    "        \n",
    "        #Save best model, AIC and params\n",
    "        if aic < best_aic:\n",
    "            best_model = model\n",
    "            best_aic = aic\n",
    "            best_param = param\n",
    "        results.append([param, model.aic])\n",
    "        \n",
    "    result_tbl = pd.DataFrame(results)\n",
    "    result_tbl.columns = ['params', 'aic']\n",
    "    \n",
    "    #Sort in ascending order, lower AIC is better\n",
    "    result_tbl = result_tbl.sort_values(by='aic', ascending=True).reset_index(drop=True)\n",
    "    return result_tbl\n",
    "\n",
    "result_tbl = optimize_SARIMA(params_list, d, D, s)\n",
    "\n",
    "#Set params that give the lowest AIC (Akaike Information Criteria)\n",
    "p, q, P, Q = result_tbl.params[0]\n",
    "best_model = sm.tsa.statespace.SARIMAX(data.CLOSE, order=(p, d, q), seasonal_order=(P, D, Q, s)).fit(disp=-1)\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe containing actual and predicted prices\n",
    "comparison = pd.DataFrame({'actual': [18.93, 19.23, 19.08, 19.17, 19.11, 19.12],\n",
    "                          'predicted': [18.96, 18.97, 18.96, 18.92, 18.94, 18.92]}, \n",
    "                          index = pd.date_range(start='2018-06-05', periods=6,))\n",
    "\n",
    "#predicted vs actual\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(comparison.actual)\n",
    "plt.plot(comparison.predicted)\n",
    "plt.title('Predicted closing price of New GF Inc (GF)')\n",
    "plt.ylabel('Closing price ($)')\n",
    "plt.xlabel('Trading day')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
